{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNF/uS18g55Y+acEqDRa+bA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VwqjwwwByj8l","executionInfo":{"status":"ok","timestamp":1709313180698,"user_tz":-60,"elapsed":27092,"user":{"displayName":"Nasko Hristov","userId":"09686283403315403814"}},"outputId":"6b9d06dd-fb2e-4e99-b94c-bb59a279865d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["pip install pyspark"],"metadata":{"id":"ty6P_eqgzV4v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709313233499,"user_tz":-60,"elapsed":52806,"user":{"displayName":"Nasko Hristov","userId":"09686283403315403814"}},"outputId":"f359c324-fc62-441b-c949-e525846d5716"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyspark\n","  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488493 sha256=6c412dbb84cdbbc8cccde6977c446c57a564563b469ad81ffd73c8481d644929\n","  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.5.1\n"]}]},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, collect_set, format_number, max\n","import pandas as pd\n","from pyspark.ml.feature import StringIndexer, OneHotEncoder\n","from pyspark.ml import Pipeline\n","\n","spark = SparkSession.builder\\\n","  .master(\"local\")\\\n","  .appName(\"Pyspark_SQL\")\\\n","  .config(\"spark.ui.port\", '4050')\\\n","  .getOrCreate()\n","df = spark.read.option(\"Header\", True).csv(\"/content/Air_Traffic_Passenger_Statistics.csv\")"],"metadata":{"id":"esOC9u4Rzum8","executionInfo":{"status":"ok","timestamp":1709313260092,"user_tz":-60,"elapsed":26616,"user":{"displayName":"Nasko Hristov","userId":"09686283403315403814"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from pyspark.sql.functions import mean, stddev\n","\n","columns_to_cast = ['Activity Period', 'Passenger Count', 'Adjusted Passenger Count', 'year']\n","\n","for column in columns_to_cast:\n","    df = df.withColumn(column, col(column).cast('double'))\n","\n","numeric_columns = [column for column, dtype in df.dtypes if dtype in [\"int\", \"double\", \"float\"]]\n","\n","for column in numeric_columns:\n","    df.select(mean(col(column)).alias('mean_' + column),\n","              stddev(col(column)).alias('stddev_' + column)).show()"],"metadata":{"id":"uzmpJYu6MCA_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709313265952,"user_tz":-60,"elapsed":5878,"user":{"displayName":"Nasko Hristov","userId":"09686283403315403814"}},"outputId":"06776895-9750-497e-c8e5-12ba1e60f5bd"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+----------------------+\n","|mean_Activity Period|stddev_Activity Period|\n","+--------------------+----------------------+\n","|  201045.07336576266|    313.33619609986414|\n","+--------------------+----------------------+\n","\n","+--------------------+----------------------+\n","|mean_Passenger Count|stddev_Passenger Count|\n","+--------------------+----------------------+\n","|  29240.521090157927|    58319.509284123524|\n","+--------------------+----------------------+\n","\n","+-----------------------------+-------------------------------+\n","|mean_Adjusted Passenger Count|stddev_Adjusted Passenger Count|\n","+-----------------------------+-------------------------------+\n","|           29331.917105350836|               58284.1822186625|\n","+-----------------------------+-------------------------------+\n","\n","+-----------------+-----------------+\n","|        mean_year|      stddev_year|\n","+-----------------+-----------------+\n","|2010.385220230559|3.137589043169972|\n","+-----------------+-----------------+\n","\n"]}]},{"cell_type":"code","source":["numeric_columns = [column for column, dtype in df.dtypes if dtype in ['double', 'float', 'int']]\n","correlation_matrix = []\n","\n","for x in numeric_columns:\n","    row = []\n","    for y in numeric_columns:\n","        row.append(df.stat.corr(x, y))\n","    correlation_matrix.append(row)\n","\n","import pandas as pd\n","\n","correlation_df = pd.DataFrame(correlation_matrix, columns=numeric_columns, index=numeric_columns)\n","print(correlation_df)\n"],"metadata":{"id":"0CY8G-aSFlf3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709313281664,"user_tz":-60,"elapsed":15716,"user":{"displayName":"Nasko Hristov","userId":"09686283403315403814"}},"outputId":"bead83a4-cc6c-4be6-cf4c-8e2c2e8623ea"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["                          Activity Period  Passenger Count  \\\n","Activity Period                  1.000000         0.060311   \n","Passenger Count                  0.060311         1.000000   \n","Adjusted Passenger Count         0.059336         0.999941   \n","year                             0.999940         0.060069   \n","\n","                          Adjusted Passenger Count      year  \n","Activity Period                           0.059336  0.999940  \n","Passenger Count                           0.999941  0.060069  \n","Adjusted Passenger Count                  1.000000  0.059096  \n","year                                      0.059096  1.000000  \n"]}]},{"cell_type":"code","source":["\n","from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n","from pyspark.ml.regression import LinearRegression\n","from pyspark.ml import Pipeline\n","from pyspark.ml.evaluation import RegressionEvaluator\n","from pyspark.sql.functions import col\n","\n","columns_to_cast = ['Activity Period', 'Passenger Count', 'Adjusted Passenger Count', 'year']\n","all_columns = df.columns\n","for column in columns_to_cast:\n","    df = df.withColumn(column, col(column).cast('double'))\n","\n","numeric_columns = ['Activity Period', 'Adjusted Passenger Count', 'year']\n","categorical_columns = [col for col in all_columns if col not in columns_to_cast]\n","\n","indexers = [\n","    StringIndexer(inputCol=c, outputCol=c+\"_index\", handleInvalid=\"keep\")\n","    for c in categorical_columns\n","]\n","\n","encoders = [\n","    OneHotEncoder(inputCol=c+\"_index\", outputCol=c+\"_vec\")\n","    for c in categorical_columns\n","]\n","\n","assemblerInputs = [c + \"_vec\" for c in categorical_columns] + numeric_columns\n","\n","vecAssembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n","\n","lr = LinearRegression(featuresCol=\"features\", labelCol=\"Passenger Count\")\n","\n","pipeline = Pipeline(stages=indexers + encoders + [vecAssembler, lr])\n","\n","(train_data, test_data) = df.randomSplit([0.8, 0.2])\n","model = pipeline.fit(train_data)\n","\n","predictions = model.transform(test_data)\n","evaluator_rmse = RegressionEvaluator(labelCol=\"Passenger Count\", predictionCol=\"prediction\", metricName=\"rmse\")\n","evaluator_r2 = RegressionEvaluator(labelCol=\"Passenger Count\", predictionCol=\"prediction\", metricName=\"r2\")\n","\n","rmse = evaluator_rmse.evaluate(predictions)\n","r2 = evaluator_r2.evaluate(predictions)\n","\n","print(f\"RMSE: {rmse}\")\n","print(f\"R2: {r2}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SFZLCuO40Wyx","executionInfo":{"status":"ok","timestamp":1709314332831,"user_tz":-60,"elapsed":27348,"user":{"displayName":"Nasko Hristov","userId":"09686283403315403814"}},"outputId":"2e85681c-98db-4198-e071-08885a13c64f"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["RMSE: 504.1521658099943\n","R2: 0.9999292132013743\n"]}]}]}